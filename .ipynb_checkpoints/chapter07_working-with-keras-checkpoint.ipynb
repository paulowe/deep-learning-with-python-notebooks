{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.1327675 , -0.25208524, -0.22056574,  0.23584145, -0.11756137,\n",
       "         -0.28210023,  0.15773475, -0.07287148, -0.22948723, -0.25278667,\n",
       "         -0.04438287, -0.28504255,  0.2877438 ,  0.2982369 , -0.09268816,\n",
       "         -0.16894515, -0.08841808, -0.0293873 , -0.19675052, -0.10990593,\n",
       "          0.04774421,  0.15373659,  0.16087726, -0.03396517,  0.08485264,\n",
       "         -0.24837616, -0.16488063, -0.01197609,  0.25704902,  0.00739729,\n",
       "         -0.2547537 , -0.01047394,  0.15967977,  0.20963866,  0.26913214,\n",
       "          0.10600179, -0.01334569,  0.08830008,  0.10420656, -0.08503978,\n",
       "          0.12329841,  0.14135844,  0.1519975 ,  0.24294323, -0.18010567,\n",
       "         -0.29037875, -0.19992627, -0.29665107,  0.05257791, -0.05035523,\n",
       "         -0.05624746, -0.12177472, -0.15855011,  0.10492361,  0.01639849,\n",
       "          0.01558676,  0.250831  ,  0.0019156 , -0.14579377,  0.22473568,\n",
       "         -0.02681023, -0.07968052, -0.2366378 ,  0.06533697],\n",
       "        [-0.24157077,  0.2788974 ,  0.03194866, -0.24222252,  0.15251768,\n",
       "          0.13617742, -0.22497785,  0.0242871 , -0.28230816, -0.20670348,\n",
       "         -0.10987291,  0.00449088,  0.01211086, -0.23984566,  0.20429248,\n",
       "         -0.14327057,  0.28231364,  0.03629687,  0.16930181,  0.01394686,\n",
       "          0.00420907, -0.14033926,  0.24630189,  0.19407555, -0.24987745,\n",
       "         -0.22783881,  0.14744318,  0.12298277, -0.03576669, -0.26375082,\n",
       "          0.03749698, -0.2869211 ,  0.11247614,  0.07304534, -0.03622544,\n",
       "         -0.08352464,  0.04985872, -0.06429316,  0.29272842,  0.21627676,\n",
       "         -0.11643222,  0.14597449, -0.13154711,  0.14637932,  0.19992056,\n",
       "         -0.13707417, -0.03242877,  0.19994089, -0.15682258,  0.2063117 ,\n",
       "          0.08835438, -0.13135247,  0.0544132 ,  0.11474344,  0.2645433 ,\n",
       "          0.12294719,  0.02648973, -0.290282  , -0.18159026, -0.17017055,\n",
       "          0.00922766,  0.17290735,  0.19604376,  0.21134931],\n",
       "        [ 0.24380225, -0.06164725, -0.23482943, -0.2807888 ,  0.04400387,\n",
       "          0.04773813,  0.12374741, -0.05996466,  0.00377071, -0.05794838,\n",
       "          0.03215587,  0.10338515, -0.02430314, -0.21695974,  0.14759642,\n",
       "          0.21447343,  0.01065373,  0.23119855, -0.0931721 ,  0.1472187 ,\n",
       "         -0.24742047, -0.29191452,  0.02901834, -0.1587008 , -0.2273032 ,\n",
       "         -0.11939864,  0.19248351, -0.26283473, -0.07427239,  0.00449523,\n",
       "         -0.02864242,  0.09273654,  0.2762568 , -0.25801584, -0.27115732,\n",
       "          0.28394085, -0.11177188, -0.01255444, -0.24175313,  0.21909255,\n",
       "         -0.24118377,  0.17852461, -0.06901573, -0.20273536, -0.22453201,\n",
       "          0.16393542, -0.22814995, -0.21182153, -0.17123903, -0.01513499,\n",
       "         -0.27731034,  0.22448313,  0.19955325,  0.21153569, -0.20808677,\n",
       "         -0.06230478,  0.16629672,  0.25945604, -0.03281325,  0.21148813,\n",
       "          0.10512045,  0.04424512,  0.07927775,  0.17752224]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-2.06827983e-01, -2.37940118e-01, -4.39581275e-03,\n",
       "          1.25032872e-01,  4.30789590e-03, -2.03088045e-01,\n",
       "          2.40267903e-01,  2.42954046e-01, -1.37029395e-01,\n",
       "         -7.94721693e-02],\n",
       "        [ 1.34047776e-01, -1.37029603e-01, -1.90357566e-02,\n",
       "          1.52420938e-01,  2.50289589e-01,  9.16326046e-03,\n",
       "         -2.16678008e-01, -7.74064660e-03,  1.48963273e-01,\n",
       "         -1.24828100e-01],\n",
       "        [ 2.11942762e-01, -2.72178262e-01, -1.28881827e-01,\n",
       "         -7.55293071e-02,  5.98279834e-02,  2.73674726e-04,\n",
       "          1.76933706e-01, -3.09009254e-02,  2.58912742e-02,\n",
       "          1.32747084e-01],\n",
       "        [ 2.89622247e-02, -4.78218794e-02, -4.44513857e-02,\n",
       "         -1.64532155e-01,  2.03151792e-01, -1.96032539e-01,\n",
       "          9.92920399e-02, -1.43338472e-01, -1.17645100e-01,\n",
       "         -1.54241920e-02],\n",
       "        [ 1.09238118e-01,  1.70237064e-01,  1.54549927e-01,\n",
       "         -2.09084272e-01,  1.78831220e-01,  2.29408175e-01,\n",
       "         -2.11810768e-01,  2.64269561e-01, -1.98670626e-02,\n",
       "         -1.30162224e-01],\n",
       "        [ 1.00551456e-01,  2.18524903e-01,  1.37902588e-01,\n",
       "          1.80731684e-01,  6.93727732e-02, -7.53066987e-02,\n",
       "          1.13039702e-01, -2.17049837e-01,  3.90609205e-02,\n",
       "         -1.52615234e-01],\n",
       "        [ 1.99962556e-02,  7.03475475e-02,  2.09783673e-01,\n",
       "         -9.54928994e-03, -1.09895021e-01,  1.75825030e-01,\n",
       "         -2.22310364e-01, -5.47701120e-03,  2.65795320e-01,\n",
       "          5.24676740e-02],\n",
       "        [-2.74821401e-01,  1.47345483e-01, -5.88104725e-02,\n",
       "          2.40176022e-02, -1.39043808e-01, -1.73924863e-01,\n",
       "          2.02854514e-01,  1.97929710e-01,  2.32234746e-01,\n",
       "         -4.94969040e-02],\n",
       "        [ 1.23598784e-01,  1.83156818e-01,  1.16083175e-01,\n",
       "         -1.34668022e-01, -1.43087611e-01,  2.22950548e-01,\n",
       "         -1.93282828e-01,  2.83838362e-01, -4.85500544e-02,\n",
       "          8.89278352e-02],\n",
       "        [ 8.12439919e-02,  2.29192287e-01,  5.72273731e-02,\n",
       "          2.45165974e-01, -4.19798493e-03, -5.34199327e-02,\n",
       "         -2.46174514e-01, -2.36921996e-01,  2.84306496e-01,\n",
       "          1.25630617e-01],\n",
       "        [ 2.23102123e-01,  1.28427982e-01, -9.74139571e-02,\n",
       "         -4.48084772e-02, -1.32104054e-01,  2.36284643e-01,\n",
       "         -1.44980982e-01, -2.68163979e-02, -1.28621608e-01,\n",
       "          7.37235844e-02],\n",
       "        [ 1.91054642e-01,  1.44819319e-01, -1.70396000e-01,\n",
       "          2.44542748e-01, -6.54815882e-02,  2.04960406e-02,\n",
       "         -1.43546134e-01, -1.79316968e-01,  1.97135329e-01,\n",
       "         -1.79742083e-01],\n",
       "        [ 1.05038166e-01,  2.41487652e-01,  1.87505454e-01,\n",
       "         -1.06123984e-01,  1.83438987e-01, -7.29402155e-02,\n",
       "         -1.90684438e-01,  2.39594966e-01, -2.57597119e-01,\n",
       "          1.38556987e-01],\n",
       "        [-1.85798794e-01,  1.07928962e-01, -5.20204008e-02,\n",
       "          4.87003624e-02,  2.34608382e-01, -2.38013029e-01,\n",
       "         -1.00997075e-01, -2.51735330e-01, -1.63628668e-01,\n",
       "          9.35963392e-02],\n",
       "        [ 3.00045907e-02,  2.76203901e-01, -2.16315746e-01,\n",
       "         -2.90229917e-02, -3.28507721e-02,  1.74680144e-01,\n",
       "          5.89370131e-02,  1.35399669e-01,  2.26377338e-01,\n",
       "         -2.31184691e-01],\n",
       "        [-1.42633304e-01,  1.90967262e-01,  8.74434412e-02,\n",
       "         -2.37511188e-01, -3.21533382e-02,  2.50934750e-01,\n",
       "         -1.29586652e-01,  3.10230553e-02, -5.06176800e-02,\n",
       "          2.72430509e-01],\n",
       "        [-8.48886222e-02,  9.00006294e-03,  2.22442418e-01,\n",
       "          1.30154073e-01, -1.56172767e-01,  5.03345132e-02,\n",
       "          2.57185489e-01,  1.48480833e-02,  2.71988600e-01,\n",
       "         -2.60999918e-01],\n",
       "        [ 1.17660522e-01, -2.25286409e-01, -1.30284429e-02,\n",
       "         -2.81827897e-01,  2.15358049e-01, -1.38097018e-01,\n",
       "          1.17573828e-01, -5.89666069e-02, -4.26050127e-02,\n",
       "          9.51471329e-02],\n",
       "        [-2.86937356e-02,  1.40977502e-01,  1.85179234e-01,\n",
       "         -2.57847905e-01,  2.42033511e-01, -2.68004656e-01,\n",
       "         -2.03225315e-02,  1.35927618e-01, -1.08231679e-01,\n",
       "         -2.71106780e-01],\n",
       "        [-2.63701439e-01,  2.35438555e-01, -4.84098643e-02,\n",
       "         -1.53362900e-01, -2.53198743e-01,  1.14234835e-01,\n",
       "          1.12636685e-02, -1.41706407e-01,  6.33119345e-02,\n",
       "          2.12601274e-01],\n",
       "        [-1.08916610e-01,  9.77135599e-02,  2.83968717e-01,\n",
       "          1.29430562e-01, -2.17068106e-01, -1.87306136e-01,\n",
       "          2.82321066e-01,  1.05706871e-01, -1.51822969e-01,\n",
       "         -4.16292995e-02],\n",
       "        [-8.62620175e-02, -4.91245240e-02,  2.70083874e-01,\n",
       "         -9.19029266e-02, -6.42647445e-02,  2.07367539e-03,\n",
       "          1.47089809e-01,  1.49974495e-01, -5.64216524e-02,\n",
       "         -1.47615746e-01],\n",
       "        [ 1.99557215e-01, -1.37468025e-01, -2.26208746e-01,\n",
       "         -2.82463670e-01, -1.58583432e-01,  1.80708349e-01,\n",
       "          1.28593832e-01, -6.44973963e-02, -1.88099146e-01,\n",
       "          4.13165390e-02],\n",
       "        [ 3.74704897e-02,  2.46528357e-01,  1.78514451e-01,\n",
       "         -1.65918022e-01,  1.65262073e-01,  1.41590178e-01,\n",
       "          1.86893314e-01, -2.55709141e-01,  1.41049027e-02,\n",
       "          1.71776235e-01],\n",
       "        [-2.01534808e-01, -2.14002162e-01,  2.36727446e-01,\n",
       "          2.67402828e-02,  7.61583745e-02, -2.12287903e-03,\n",
       "          5.58110476e-02, -5.94302267e-02,  1.36073738e-01,\n",
       "         -1.58790365e-01],\n",
       "        [ 1.35470182e-01,  1.33101881e-01, -1.67562723e-01,\n",
       "          1.67366862e-01, -2.08722085e-01,  2.61835128e-01,\n",
       "         -1.73911422e-01, -2.58065432e-01,  1.91187501e-01,\n",
       "         -1.63199812e-01],\n",
       "        [-5.86763918e-02,  4.53748107e-02, -2.12220550e-01,\n",
       "          8.02909732e-02,  1.18319929e-01, -2.45062023e-01,\n",
       "         -2.44161680e-01,  2.61136383e-01, -3.98586839e-02,\n",
       "         -2.08451748e-01],\n",
       "        [ 2.49866456e-01,  7.79702663e-02, -2.84278154e-01,\n",
       "          5.49821258e-02, -1.11678839e-02, -1.87028468e-01,\n",
       "          1.26411885e-01,  1.93418264e-01,  1.83512986e-01,\n",
       "          1.19305819e-01],\n",
       "        [ 6.10049069e-02,  8.52807462e-02, -1.39173865e-02,\n",
       "         -2.33330652e-01,  1.44878328e-01, -4.19096798e-02,\n",
       "         -3.32248211e-03, -1.73550457e-01, -8.11841190e-02,\n",
       "         -6.65918440e-02],\n",
       "        [-1.33263052e-01, -5.73479980e-02,  1.16208225e-01,\n",
       "          2.52825826e-01,  1.56107038e-01, -2.59549409e-01,\n",
       "         -1.31616056e-01,  2.45169312e-01, -1.67681932e-01,\n",
       "         -1.03804469e-02],\n",
       "        [ 2.94277370e-02,  2.06727564e-01,  2.02498227e-01,\n",
       "         -1.28292546e-01,  2.56742626e-01,  3.57369483e-02,\n",
       "          1.26646936e-01, -1.74762011e-01, -4.03727442e-02,\n",
       "          2.21182674e-01],\n",
       "        [ 2.31981725e-01, -2.63553113e-01, -2.04440057e-01,\n",
       "         -1.89401403e-01,  1.66336238e-01, -1.37232870e-01,\n",
       "          7.31322169e-03, -4.16520238e-03, -1.64890394e-01,\n",
       "         -1.32574514e-01],\n",
       "        [-2.31674492e-01,  2.59552330e-01, -1.11466661e-01,\n",
       "          1.50314689e-01, -1.16111621e-01, -1.84130698e-01,\n",
       "          1.35150760e-01,  3.24988961e-02, -1.09528765e-01,\n",
       "          2.51199096e-01],\n",
       "        [-1.06376261e-01,  1.20660543e-01,  1.94281399e-01,\n",
       "          1.60420716e-01,  1.00028783e-01,  1.56781107e-01,\n",
       "         -1.17743745e-01,  2.42601037e-02, -1.94456220e-01,\n",
       "         -6.50155991e-02],\n",
       "        [ 9.32693481e-03, -2.28888407e-01,  2.63962418e-01,\n",
       "          1.54394001e-01,  1.02065861e-01, -4.62659299e-02,\n",
       "         -2.02607393e-01,  5.75396419e-02,  1.67147428e-01,\n",
       "         -1.68899506e-01],\n",
       "        [ 2.63786167e-01, -2.32206285e-01,  9.00191367e-02,\n",
       "         -1.80877179e-01, -1.19648442e-01,  3.98786366e-02,\n",
       "          1.53181851e-01, -1.79802835e-01, -8.79930556e-02,\n",
       "         -1.37986362e-01],\n",
       "        [-2.39643753e-02, -1.28213197e-01,  1.80326611e-01,\n",
       "          4.89385128e-02, -1.23468697e-01, -2.02506781e-03,\n",
       "          4.32405174e-02,  2.74418801e-01, -1.94225252e-01,\n",
       "         -8.65797400e-02],\n",
       "        [-3.58957946e-02, -1.13331363e-01, -2.60479212e-01,\n",
       "         -2.46319741e-01, -2.66155690e-01,  2.19114125e-02,\n",
       "         -7.83157498e-02, -1.25977814e-01, -2.74835169e-01,\n",
       "          2.08223045e-01],\n",
       "        [ 1.64136082e-01,  1.35231018e-02, -1.92156881e-01,\n",
       "         -2.20244765e-01,  4.16612923e-02,  2.86984742e-02,\n",
       "          7.10052252e-03,  1.70164824e-01,  8.34403634e-02,\n",
       "         -2.23289594e-01],\n",
       "        [ 5.28257787e-02,  2.73746639e-01, -2.83909023e-01,\n",
       "         -2.03463137e-01,  1.14448130e-01,  1.96142584e-01,\n",
       "         -1.78878397e-01, -2.32804984e-01,  2.79117227e-02,\n",
       "          2.27709323e-01],\n",
       "        [ 1.87116802e-01,  1.10239685e-02, -2.16808081e-01,\n",
       "         -5.66523373e-02,  6.27548993e-02,  5.58260679e-02,\n",
       "          1.30503565e-01,  9.87356901e-02, -1.27983451e-01,\n",
       "          9.67653990e-02],\n",
       "        [-4.09191847e-02, -5.63460886e-02, -2.07856983e-01,\n",
       "          7.63998330e-02,  1.08794332e-01,  8.47706497e-02,\n",
       "          2.41005152e-01, -1.75448433e-01,  8.87911618e-02,\n",
       "         -1.53448433e-01],\n",
       "        [-1.76085100e-01, -1.55995771e-01, -1.76920682e-01,\n",
       "          1.17461592e-01, -1.03232861e-01, -1.18085086e-01,\n",
       "          1.43596441e-01, -2.22905129e-01,  2.26012975e-01,\n",
       "          1.62405849e-01],\n",
       "        [ 1.68791443e-01,  4.76032495e-04, -2.75628060e-01,\n",
       "          4.60137725e-02, -2.10314974e-01,  2.35754281e-01,\n",
       "         -2.28060842e-01,  2.67758638e-01,  1.20032817e-01,\n",
       "          2.05971897e-02],\n",
       "        [ 1.30519599e-01,  2.38273174e-01, -2.11802214e-01,\n",
       "         -1.01141676e-01,  1.34777576e-01, -3.04720700e-02,\n",
       "          7.64077306e-02, -2.40329608e-01, -2.31413543e-02,\n",
       "         -2.19763637e-01],\n",
       "        [ 2.63780922e-01,  1.84291810e-01,  7.04975128e-02,\n",
       "         -8.49519670e-02,  2.33306289e-02, -1.89181238e-01,\n",
       "          1.01805091e-01, -2.18139112e-01, -2.39763260e-02,\n",
       "          1.00721031e-01],\n",
       "        [ 2.01211721e-01, -1.98067784e-01,  1.37496829e-01,\n",
       "         -3.12580168e-02,  2.49006778e-01, -1.98832691e-01,\n",
       "         -2.35038549e-01, -9.86352861e-02,  8.11741352e-02,\n",
       "         -1.44120276e-01],\n",
       "        [ 6.30752444e-02,  2.35611349e-01, -2.09870428e-01,\n",
       "         -4.05768901e-02, -2.81311393e-01,  1.16802394e-01,\n",
       "         -1.47660494e-01, -1.77337587e-01, -2.40761116e-01,\n",
       "         -6.15825206e-02],\n",
       "        [ 2.13759810e-01,  2.00780958e-01, -1.57414973e-02,\n",
       "         -2.10224211e-01,  2.64896303e-01,  2.09194660e-01,\n",
       "          8.11171234e-02, -1.90535486e-02, -8.87241513e-02,\n",
       "         -1.62234515e-01],\n",
       "        [-1.43147409e-02,  1.53445184e-01,  3.58256102e-02,\n",
       "         -3.12167406e-03, -3.82959545e-02, -1.86871320e-01,\n",
       "         -9.05160159e-02, -1.14546105e-01,  4.55321670e-02,\n",
       "         -1.82342499e-01],\n",
       "        [-2.91473567e-02, -8.56051892e-02,  8.00315142e-02,\n",
       "         -1.44652933e-01,  2.52769738e-01, -8.37774128e-02,\n",
       "          1.35855466e-01, -5.62119484e-02,  2.31759280e-01,\n",
       "          2.69732803e-01],\n",
       "        [-1.17032275e-01, -2.54386038e-01, -2.08173692e-01,\n",
       "         -2.25638419e-01, -7.09994733e-02, -1.88463718e-01,\n",
       "          2.17627078e-01,  1.68834955e-01, -1.99004591e-01,\n",
       "          1.68751448e-01],\n",
       "        [-1.06443807e-01,  1.76473230e-01, -7.66209662e-02,\n",
       "          1.70062512e-01, -1.92200392e-01, -7.53020048e-02,\n",
       "         -2.17663020e-01,  1.53988361e-01, -2.14816764e-01,\n",
       "         -1.62201717e-01],\n",
       "        [-3.81205976e-02, -2.36971200e-01,  9.10977721e-02,\n",
       "          6.09928966e-02,  1.56198680e-01,  2.30879784e-02,\n",
       "         -6.12850934e-02,  7.59384036e-02,  4.96953726e-03,\n",
       "         -1.23777524e-01],\n",
       "        [ 2.26405859e-02, -1.30922779e-01,  6.61492646e-02,\n",
       "         -1.21272415e-01, -1.63338780e-01,  2.04976320e-01,\n",
       "         -1.70862317e-01,  2.13874876e-02,  9.79587734e-02,\n",
       "         -1.36687756e-02],\n",
       "        [ 2.84058243e-01, -8.60528499e-02, -7.71201551e-02,\n",
       "          1.03103399e-01,  1.98354900e-01,  1.26250178e-01,\n",
       "          1.52757883e-01, -1.05504021e-01,  1.03862673e-01,\n",
       "         -1.31885037e-01],\n",
       "        [ 1.77976757e-01, -1.76090330e-01, -2.59985000e-01,\n",
       "         -1.41218901e-01,  2.31129259e-01,  1.81357831e-01,\n",
       "          2.67540514e-02,  5.80024421e-02, -6.57932609e-02,\n",
       "         -1.09568208e-01],\n",
       "        [-8.32616687e-02, -9.20719653e-02, -1.51270837e-01,\n",
       "          2.20955044e-01,  1.78283751e-01,  1.41367048e-01,\n",
       "          2.42606729e-01,  2.11735696e-01, -4.09280807e-02,\n",
       "         -1.73179507e-02],\n",
       "        [ 2.36363322e-01,  1.27027243e-01,  2.29495019e-01,\n",
       "         -2.49878764e-02, -3.76998931e-02, -1.96377411e-01,\n",
       "          5.05626798e-02,  9.47969556e-02,  5.06700873e-02,\n",
       "         -2.36649066e-01],\n",
       "        [ 3.92775536e-02, -9.70675200e-02, -1.56940922e-01,\n",
       "          2.07013875e-01, -5.26388139e-02,  1.36231571e-01,\n",
       "         -5.18593043e-02,  1.09120548e-01,  2.42280275e-01,\n",
       "          9.67900455e-02],\n",
       "        [-2.83192188e-01,  1.74991935e-01,  1.47752076e-01,\n",
       "         -2.75654197e-02, -7.11108148e-02, -9.95897949e-02,\n",
       "         -1.39359489e-01,  2.91903913e-02, -1.43796250e-01,\n",
       "          3.44112813e-02],\n",
       "        [-1.37243792e-01,  2.49488950e-02,  7.87684321e-02,\n",
       "          2.12654471e-03, -4.39591855e-02, -1.93878084e-01,\n",
       "         -1.79451704e-03, -1.71076983e-01, -1.89143419e-01,\n",
       "         -1.05287135e-02],\n",
       "        [-3.79310548e-02, -2.64044493e-01, -5.48371226e-02,\n",
       "          1.11414313e-01, -1.88254893e-01,  2.35236436e-01,\n",
       "          2.42376894e-01,  2.06330150e-01, -2.21056581e-01,\n",
       "         -8.77642035e-02],\n",
       "        [-1.90308005e-01, -2.23947912e-01,  1.55148238e-01,\n",
       "         -8.39520246e-02, -8.21275115e-02,  3.28021646e-02,\n",
       "         -1.86527938e-01,  2.36907870e-01, -1.86935470e-01,\n",
       "          1.38822883e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs) # Use Model API - Model groups layers into an object with training and inference features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
